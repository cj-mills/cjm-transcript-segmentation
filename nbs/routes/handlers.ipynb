{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dh-title",
   "metadata": {},
   "source": [
    "# handlers\n",
    "\n",
    "> Segmentation workflow handlers — init, split, merge, undo, reset, AI split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-default-exp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp routes.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-imports",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nfrom typing import List, Dict, Any, Tuple, Callable, Optional, NamedTuple\n\nfrom fasthtml.common import APIRouter, Script, Div\n\nfrom cjm_fasthtml_card_stack.core.models import CardStackState\nfrom cjm_fasthtml_card_stack.core.constants import DEFAULT_VISIBLE_COUNT, DEFAULT_CARD_WIDTH\n\nfrom cjm_fasthtml_interactions.core.state_store import get_session_id\nfrom cjm_workflow_state.history import pop_history\n\nfrom cjm_transcript_segmentation.models import TextSegment, SegmentationUrls\nfrom cjm_transcript_segmentation.components.step_renderer import (\n    render_seg_column_body, render_seg_stats, render_toolbar,\n    render_seg_source_position,\n)\nfrom cjm_transcript_segmentation.components.card_stack_config import (\n    SEG_CS_IDS, SEG_TS_IDS,\n)\nfrom cjm_transcript_segmentation.utils import (\n    word_index_to_char_position,\n)\nfrom cjm_transcript_segmentation.services.segmentation import (\n    SegmentationService, split_segment_at_position, merge_text_segments,\n    reindex_segments, reconstruct_source_blocks,\n)\nfrom cjm_transcript_segmentation.routes.core import (\n    WorkflowStateStore, DEFAULT_MAX_HISTORY_DEPTH,\n    _to_segments, _load_seg_context, _get_seg_state,\n    _get_selection_state, _update_seg_state, _push_history,\n    _build_card_stack_state,\n)\nfrom cjm_transcript_segmentation.routes.card_stack import (\n    _build_slots_oob, _build_nav_response\n)\nfrom cjm_transcript_source_select.services.source import SourceService\nfrom cjm_transcript_segmentation.html_ids import SegmentationHtmlIds\n\n# Debug flag for segmentation handler tracing (set False in production)\nDEBUG_SEG_HANDLERS = True"
  },
  {
   "cell_type": "markdown",
   "id": "dh-mutation-header",
   "metadata": {},
   "source": [
    "## Mutation Response Builder\n",
    "\n",
    "Assembles the full OOB response for handlers that mutate segment data.\n",
    "Includes decomposition-specific elements (stats, toolbar) in addition to card stack elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-mutation-response",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef _build_mutation_response(\n    segment_dicts:List[Dict[str, Any]],  # Serialized segments\n    focused_index:int,  # Currently focused segment index\n    visible_count:int,  # Number of visible cards\n    history_depth:int,  # Current undo history depth\n    urls:SegmentationUrls,  # URL bundle\n    is_split_mode:bool=False,  # Whether split mode is active\n    is_auto_mode:bool=False,  # Whether card count is in auto-adjust mode\n) -> Tuple:  # OOB elements (slots + progress + focus + stats + toolbar + source position)\n    \"\"\"Build the standard OOB response for mutation handlers.\n    \n    Returns domain-specific OOB elements. The combined layer wrapper\n    adds cross-domain elements (mini-stats badge, alignment status).\n    \"\"\"\n    state = CardStackState(\n        focused_index=focused_index,\n        visible_count=visible_count,\n        active_mode=\"split\" if is_split_mode else None,\n    )\n\n    # Library handles: slots + progress + focus\n    nav_response = _build_nav_response(segment_dicts, state, urls)\n\n    # Segmentation-specific OOB elements\n    segments = _to_segments(segment_dicts)\n    stats_oob = render_seg_stats(segments, oob=True)\n    toolbar_oob = render_toolbar(\n        reset_url=urls.reset, ai_split_url=urls.ai_split, undo_url=urls.undo,\n        can_undo=(history_depth > 0), visible_count=visible_count,\n        is_auto_mode=is_auto_mode, oob=True,\n    )\n    source_pos_oob = render_seg_source_position(segments, focused_index, oob=True)\n\n    return (*nav_response, stats_oob, toolbar_oob, source_pos_oob)"
  },
  {
   "cell_type": "markdown",
   "id": "dh-init-header",
   "metadata": {},
   "source": [
    "## Initialize Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u4t7lcufnfg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SegInitResult(NamedTuple):\n",
    "    \"\"\"Result from pure segmentation init handler.\n",
    "    \n",
    "    Contains domain-specific data for the combined layer wrapper to use\n",
    "    when building cross-domain OOB elements (KB system, shared chrome).\n",
    "    \"\"\"\n",
    "    column_body: Any  # Rendered column body content\n",
    "    segments: List[TextSegment]  # Initialized segments\n",
    "    focused_index: int  # Focused segment index (always 0 on init)\n",
    "    visible_count: int  # Visible card count\n",
    "    card_width: int  # Card stack width in rem\n",
    "    history_depth: int  # History depth (always 0 on init)\n",
    "    is_auto_mode: bool  # Whether card count is in auto-adjust mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _handle_seg_init(\n",
    "    state_store: WorkflowStateStore,  # The workflow state store\n",
    "    workflow_id: str,  # The workflow identifier\n",
    "    source_service: SourceService,  # Service for fetching source blocks\n",
    "    segmentation_service: SegmentationService,  # Service for NLTK sentence splitting\n",
    "    request,  # FastHTML request object\n",
    "    sess,  # FastHTML session object\n",
    "    urls: SegmentationUrls,  # URL bundle for segmentation routes\n",
    "    visible_count: int = DEFAULT_VISIBLE_COUNT,  # Number of visible cards\n",
    "    card_width: int = DEFAULT_CARD_WIDTH,  # Card stack width in rem\n",
    ") -> SegInitResult:  # Pure domain result for wrapper to use\n",
    "    \"\"\"Initialize segments from Phase 1 selected sources.\n",
    "    \n",
    "    Returns pure domain data. The combined layer wrapper adds cross-domain\n",
    "    coordination (KB system, shared chrome, alignment status).\n",
    "    \"\"\"\n",
    "    if DEBUG_SEG_HANDLERS:\n",
    "        print(\"[SEG_HANDLERS] _handle_seg_init called\")\n",
    "\n",
    "    session_id = get_session_id(sess)\n",
    "\n",
    "    # Get selected sources from Phase 1\n",
    "    selection_state = _get_selection_state(state_store, workflow_id, session_id)\n",
    "    selected_sources = selection_state.get(\"selected_sources\", [])\n",
    "\n",
    "    # Read stored viewport preferences (may exist from previous session)\n",
    "    seg_state = _get_seg_state(state_store, workflow_id, session_id)\n",
    "    stored_visible_count = seg_state.get(\"visible_count\", visible_count)\n",
    "    stored_is_auto_mode = seg_state.get(\"is_auto_mode\", False)\n",
    "    stored_card_width = seg_state.get(\"card_width\", card_width)\n",
    "\n",
    "    if not selected_sources:\n",
    "        # No sources selected, initialize with empty state\n",
    "        _update_seg_state(\n",
    "            state_store, workflow_id, session_id,\n",
    "            segments=[], initial_segments=[],\n",
    "            is_initialized=True, focused_index=0,\n",
    "            history=[], visible_count=stored_visible_count,\n",
    "            card_width=stored_card_width,\n",
    "        )\n",
    "        segments = []\n",
    "    else:\n",
    "        # Fetch source blocks via service API\n",
    "        source_blocks = source_service.get_source_blocks(selected_sources)\n",
    "\n",
    "        # Use segmentation service to split into sentences\n",
    "        working_segments = await segmentation_service.split_combined_sources_async(\n",
    "            source_blocks\n",
    "        )\n",
    "        segment_dicts = [s.to_dict() for s in working_segments]\n",
    "\n",
    "        # Store in state\n",
    "        _update_seg_state(\n",
    "            state_store, workflow_id, session_id,\n",
    "            segments=segment_dicts,\n",
    "            initial_segments=segment_dicts.copy(),\n",
    "            is_initialized=True, focused_index=0,\n",
    "            history=[], visible_count=stored_visible_count,\n",
    "            card_width=stored_card_width,\n",
    "        )\n",
    "        segments = _to_segments(segment_dicts)\n",
    "\n",
    "    focused_index = 0\n",
    "    history_depth = 0\n",
    "\n",
    "    # Render column body (KB system managed by combined layer)\n",
    "    column_body = render_seg_column_body(\n",
    "        segments=segments,\n",
    "        focused_index=focused_index,\n",
    "        visible_count=stored_visible_count,\n",
    "        card_width=stored_card_width,\n",
    "        urls=urls,\n",
    "        kb_system=None,\n",
    "    )\n",
    "\n",
    "    if DEBUG_SEG_HANDLERS:\n",
    "        print(\"[SEG_HANDLERS] Returning SegInitResult\")\n",
    "\n",
    "    return SegInitResult(\n",
    "        column_body=column_body,\n",
    "        segments=segments,\n",
    "        focused_index=focused_index,\n",
    "        visible_count=stored_visible_count,\n",
    "        card_width=stored_card_width,\n",
    "        history_depth=history_depth,\n",
    "        is_auto_mode=stored_is_auto_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dh-split-header",
   "metadata": {},
   "source": [
    "## Split Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _handle_seg_split(\n",
    "    state_store: WorkflowStateStore,  # The workflow state store\n",
    "    workflow_id: str,  # The workflow identifier\n",
    "    request,  # FastHTML request object\n",
    "    sess,  # FastHTML session object\n",
    "    segment_index: int,  # Index of segment to split\n",
    "    urls: SegmentationUrls,  # URL bundle for segmentation routes\n",
    "    max_history_depth: int = DEFAULT_MAX_HISTORY_DEPTH,  # Maximum history stack depth\n",
    "):  # OOB slot updates with stats, progress, focus, and toolbar\n",
    "    \"\"\"Split a segment at the specified word position.\"\"\"\n",
    "    session_id = get_session_id(sess)\n",
    "    ctx = _load_seg_context(state_store, workflow_id, session_id)\n",
    "\n",
    "    # Extract word index from token selector hidden input\n",
    "    form = await request.form()\n",
    "    word_index = int(form.get(SEG_TS_IDS.anchor_name, 0))\n",
    "\n",
    "    # Validate index\n",
    "    if segment_index < 0 or segment_index >= len(ctx.segment_dicts):\n",
    "        state = _build_card_stack_state(ctx)\n",
    "        return _build_slots_oob(ctx.segment_dicts, state, urls)\n",
    "\n",
    "    # Push current state to history before modification\n",
    "    history_depth = _push_history(\n",
    "        state_store, workflow_id, session_id,\n",
    "        ctx.segment_dicts, segment_index, max_history_depth,\n",
    "    )\n",
    "\n",
    "    # Get the segment and convert word index to character position\n",
    "    segment = TextSegment.from_dict(ctx.segment_dicts[segment_index])\n",
    "    char_position = word_index_to_char_position(segment.text, word_index)\n",
    "\n",
    "    # Can't split at beginning or end\n",
    "    if char_position <= 0 or char_position >= len(segment.text):\n",
    "        return _build_mutation_response(\n",
    "            ctx.segment_dicts, segment_index, ctx.visible_count, history_depth, urls,\n",
    "            is_auto_mode=ctx.is_auto_mode,\n",
    "        )\n",
    "\n",
    "    # Split the segment\n",
    "    first_seg, second_seg = split_segment_at_position(segment, char_position)\n",
    "\n",
    "    # Build and reindex new segments list\n",
    "    new_segments = ctx.segment_dicts[:segment_index]\n",
    "    new_segments.append(first_seg.to_dict())\n",
    "    new_segments.append(second_seg.to_dict())\n",
    "    new_segments.extend(ctx.segment_dicts[segment_index + 1:])\n",
    "\n",
    "    reindexed = reindex_segments(_to_segments(new_segments))\n",
    "    new_segment_dicts = [s.to_dict() for s in reindexed]\n",
    "\n",
    "    # Update state — focus moves to the new segment (second half)\n",
    "    new_focused_index = segment_index + 1\n",
    "    _update_seg_state(\n",
    "        state_store, workflow_id, session_id,\n",
    "        segments=new_segment_dicts, focused_index=new_focused_index,\n",
    "    )\n",
    "\n",
    "    return _build_mutation_response(\n",
    "        new_segment_dicts, new_focused_index, ctx.visible_count, history_depth, urls,\n",
    "        is_auto_mode=ctx.is_auto_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dh-merge-header",
   "metadata": {},
   "source": [
    "## Merge Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pg4dun6ay0l",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef _build_merge_reject_flash(\n    prev_index:int,  # Index of the segment above the boundary\n    curr_index:int,  # Index of the segment below the boundary\n) -> Div:  # OOB div containing JS that flashes both boundary cards\n    \"\"\"Build an OOB element that flashes both cards at a source boundary.\"\"\"\n    prev_id = SegmentationHtmlIds.segment_card(prev_index)\n    curr_id = SegmentationHtmlIds.segment_card(curr_index)\n    return Div(\n        Script(f\"\"\"(function() {{\n    var c1 = document.getElementById('{prev_id}');\n    var c2 = document.getElementById('{curr_id}');\n    [c1, c2].forEach(function(c) {{\n        if (c) {{ c.classList.remove('bg-base-100'); c.classList.add('bg-error'); }}\n    }});\n    setTimeout(function() {{\n        [c1, c2].forEach(function(c) {{\n            if (c) {{ c.classList.remove('bg-error'); c.classList.add('bg-base-100'); }}\n        }});\n    }}, 400);\n}})();\"\"\"),\n        id=SegmentationHtmlIds.SCRIPT_RUNNER,\n        hx_swap_oob=\"innerHTML\",\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-merge",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef _handle_seg_merge(\n    state_store: WorkflowStateStore,  # The workflow state store\n    workflow_id: str,  # The workflow identifier\n    request,  # FastHTML request object\n    sess,  # FastHTML session object\n    segment_index: int,  # Index of segment to merge (merges with previous)\n    urls: SegmentationUrls,  # URL bundle for segmentation routes\n    max_history_depth: int = DEFAULT_MAX_HISTORY_DEPTH,  # Maximum history stack depth\n):  # OOB slot updates with stats, progress, focus, and toolbar\n    \"\"\"Merge a segment with the previous segment.\"\"\"\n    session_id = get_session_id(sess)\n    ctx = _load_seg_context(state_store, workflow_id, session_id)\n    \n    # Can't merge first segment (nothing before it)\n    if segment_index <= 0 or segment_index >= len(ctx.segment_dicts):\n        state = _build_card_stack_state(ctx)\n        return _build_slots_oob(ctx.segment_dicts, state, urls)\n    \n    # Check source boundary — reject merge across different audio sources\n    prev_segment = TextSegment.from_dict(ctx.segment_dicts[segment_index - 1])\n    curr_segment = TextSegment.from_dict(ctx.segment_dicts[segment_index])\n    \n    if (prev_segment.source_id is not None and\n        curr_segment.source_id is not None and\n        prev_segment.source_id != curr_segment.source_id):\n        if DEBUG_SEG_HANDLERS:\n            print(f\"[SEG_HANDLERS] Merge rejected at source boundary: \"\n                  f\"'{prev_segment.source_id}' != '{curr_segment.source_id}'\")\n        state = _build_card_stack_state(ctx)\n        no_op = _build_slots_oob(ctx.segment_dicts, state, urls)\n        flash = _build_merge_reject_flash(segment_index - 1, segment_index)\n        return (*no_op, flash)\n    \n    # Push current state to history\n    history_depth = _push_history(\n        state_store, workflow_id, session_id,\n        ctx.segment_dicts, segment_index, max_history_depth,\n    )\n    \n    # Merge segments\n    merged = merge_text_segments(prev_segment, curr_segment)\n    \n    # Build and reindex new segments list\n    new_segments = ctx.segment_dicts[:segment_index - 1]\n    new_segments.append(merged.to_dict())\n    new_segments.extend(ctx.segment_dicts[segment_index + 1:])\n    \n    reindexed = reindex_segments(_to_segments(new_segments))\n    new_segment_dicts = [s.to_dict() for s in reindexed]\n    \n    # Update state — focus moves to merged segment (previous position)\n    new_focused_index = segment_index - 1\n    _update_seg_state(\n        state_store, workflow_id, session_id,\n        segments=new_segment_dicts, focused_index=new_focused_index,\n    )\n    \n    return _build_mutation_response(\n        new_segment_dicts, new_focused_index, ctx.visible_count, history_depth, urls,\n        is_auto_mode=ctx.is_auto_mode,\n    )"
  },
  {
   "cell_type": "markdown",
   "id": "dh-undo-header",
   "metadata": {},
   "source": [
    "## Undo Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-undo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _handle_seg_undo(\n",
    "    state_store: WorkflowStateStore,  # The workflow state store\n",
    "    workflow_id: str,  # The workflow identifier\n",
    "    request,  # FastHTML request object\n",
    "    sess,  # FastHTML session object\n",
    "    urls: SegmentationUrls,  # URL bundle for segmentation routes\n",
    "):  # OOB slot updates with stats, progress, focus, and toolbar\n",
    "    \"\"\"Undo the last operation by restoring previous state from history.\"\"\"\n",
    "    session_id = get_session_id(sess)\n",
    "    ctx = _load_seg_context(state_store, workflow_id, session_id)\n",
    "    \n",
    "    result = pop_history(ctx.history)\n",
    "    if result is None:\n",
    "        state = _build_card_stack_state(ctx)\n",
    "        return _build_slots_oob(ctx.segment_dicts, state, urls)\n",
    "    \n",
    "    snapshot, remaining_history = result\n",
    "    previous_segments = snapshot[\"segments\"]\n",
    "    new_focused_index = min(snapshot[\"focused_index\"], max(0, len(previous_segments) - 1))\n",
    "    \n",
    "    _update_seg_state(\n",
    "        state_store, workflow_id, session_id,\n",
    "        segments=previous_segments, history=remaining_history,\n",
    "        focused_index=new_focused_index,\n",
    "    )\n",
    "    \n",
    "    return _build_mutation_response(\n",
    "        previous_segments, new_focused_index, ctx.visible_count, len(remaining_history), urls,\n",
    "        is_auto_mode=ctx.is_auto_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dh-reset-header",
   "metadata": {},
   "source": [
    "## Reset Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _handle_seg_reset(\n",
    "    state_store: WorkflowStateStore,  # The workflow state store\n",
    "    workflow_id: str,  # The workflow identifier\n",
    "    request,  # FastHTML request object\n",
    "    sess,  # FastHTML session object\n",
    "    urls: SegmentationUrls,  # URL bundle for segmentation routes\n",
    "    max_history_depth: int = DEFAULT_MAX_HISTORY_DEPTH,  # Maximum history stack depth\n",
    "):  # OOB slot updates with stats, progress, focus, and toolbar\n",
    "    \"\"\"Reset segments to the initial NLTK split result.\"\"\"\n",
    "    session_id = get_session_id(sess)\n",
    "    ctx = _load_seg_context(state_store, workflow_id, session_id)\n",
    "    seg_state = _get_seg_state(state_store, workflow_id, session_id)\n",
    "    initial_segments = seg_state.get(\"initial_segments\", [])\n",
    "    \n",
    "    # Push current state to history before reset\n",
    "    history_depth = 0\n",
    "    if ctx.segment_dicts:\n",
    "        history_depth = _push_history(\n",
    "            state_store, workflow_id, session_id,\n",
    "            ctx.segment_dicts, ctx.focused_index, max_history_depth,\n",
    "        )\n",
    "    \n",
    "    # Restore initial segments — reset focus to first segment\n",
    "    _update_seg_state(\n",
    "        state_store, workflow_id, session_id,\n",
    "        segments=initial_segments.copy(), focused_index=0,\n",
    "    )\n",
    "    \n",
    "    return _build_mutation_response(\n",
    "        initial_segments, 0, ctx.visible_count, history_depth, urls,\n",
    "        is_auto_mode=ctx.is_auto_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dh-ai-split-header",
   "metadata": {},
   "source": [
    "## AI Split Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-ai-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _handle_seg_ai_split(\n",
    "    state_store: WorkflowStateStore,  # The workflow state store\n",
    "    workflow_id: str,  # The workflow identifier\n",
    "    segmentation_service: SegmentationService,  # Service for NLTK sentence splitting\n",
    "    request,  # FastHTML request object\n",
    "    sess,  # FastHTML session object\n",
    "    urls: SegmentationUrls,  # URL bundle for segmentation routes\n",
    "    max_history_depth: int = DEFAULT_MAX_HISTORY_DEPTH,  # Maximum history stack depth\n",
    "):  # OOB slot updates with stats, progress, focus, and toolbar\n",
    "    \"\"\"Re-run AI (NLTK) sentence splitting on all current text.\"\"\"\n",
    "    session_id = get_session_id(sess)\n",
    "    ctx = _load_seg_context(state_store, workflow_id, session_id)\n",
    "    \n",
    "    if not ctx.segment_dicts:\n",
    "        state = _build_card_stack_state(ctx)\n",
    "        return _build_slots_oob([], state, urls)\n",
    "    \n",
    "    # Push current state to history\n",
    "    history_depth = _push_history(\n",
    "        state_store, workflow_id, session_id,\n",
    "        ctx.segment_dicts, ctx.focused_index, max_history_depth,\n",
    "    )\n",
    "    \n",
    "    # Reconstruct source blocks from current segments\n",
    "    source_blocks = reconstruct_source_blocks(ctx.segment_dicts)\n",
    "    \n",
    "    # Re-run NLTK splitting\n",
    "    working_segments = await segmentation_service.split_combined_sources_async(\n",
    "        source_blocks\n",
    "    )\n",
    "    new_segment_dicts = [s.to_dict() for s in working_segments]\n",
    "    \n",
    "    # Update state — reset focus to first segment\n",
    "    _update_seg_state(\n",
    "        state_store, workflow_id, session_id,\n",
    "        segments=new_segment_dicts, focused_index=0,\n",
    "    )\n",
    "    \n",
    "    return _build_mutation_response(\n",
    "        new_segment_dicts, 0, ctx.visible_count, history_depth, urls,\n",
    "        is_auto_mode=ctx.is_auto_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xqwc03mmpg",
   "metadata": {},
   "source": [
    "## Router Initialization\n",
    "\n",
    "Creates the workflow router with init, split, merge, undo, reset, and AI split routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ul6toz93cyp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_workflow_router(\n",
    "    state_store: WorkflowStateStore,  # The workflow state store\n",
    "    workflow_id: str,  # The workflow identifier\n",
    "    source_service: SourceService,  # Service for fetching source blocks\n",
    "    segmentation_service: SegmentationService,  # Service for NLTK sentence splitting\n",
    "    prefix: str,  # Route prefix (e.g., \"/workflow/seg/workflow\")\n",
    "    urls: SegmentationUrls,  # URL bundle (populated after routes defined)\n",
    "    max_history_depth: int = DEFAULT_MAX_HISTORY_DEPTH,  # Maximum history stack depth\n",
    "    handler_init: Callable = None,  # Optional wrapped init handler\n",
    "    handler_split: Callable = None,  # Optional wrapped split handler\n",
    "    handler_merge: Callable = None,  # Optional wrapped merge handler\n",
    "    handler_undo: Callable = None,  # Optional wrapped undo handler\n",
    "    handler_reset: Callable = None,  # Optional wrapped reset handler\n",
    "    handler_ai_split: Callable = None,  # Optional wrapped ai_split handler\n",
    ") -> Tuple[APIRouter, Dict[str, Callable]]:  # (router, route_dict)\n",
    "    \"\"\"Initialize workflow routes for segmentation.\n",
    "    \n",
    "    Accepts optional handler overrides for wrapping with cross-domain\n",
    "    coordination (e.g., KB system, shared chrome, alignment status).\n",
    "    \"\"\"\n",
    "    router = APIRouter(prefix=prefix)\n",
    "\n",
    "    # Use provided handlers or fall back to raw domain handlers\n",
    "    _init = handler_init or _handle_seg_init\n",
    "    _split = handler_split or _handle_seg_split\n",
    "    _merge = handler_merge or _handle_seg_merge\n",
    "    _undo = handler_undo or _handle_seg_undo\n",
    "    _reset = handler_reset or _handle_seg_reset\n",
    "    _ai_split = handler_ai_split or _handle_seg_ai_split\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Workflow Operations\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    @router\n",
    "    async def init(request, sess):\n",
    "        \"\"\"Initialize segments from Phase 1 selected sources.\"\"\"\n",
    "        return await _init(\n",
    "            state_store, workflow_id, source_service, segmentation_service,\n",
    "            request, sess, urls=urls,\n",
    "        )\n",
    "\n",
    "    @router\n",
    "    async def split(request, sess, segment_index: int):\n",
    "        \"\"\"Split a segment at the specified word position.\"\"\"\n",
    "        return await _split(\n",
    "            state_store, workflow_id, request, sess, segment_index,\n",
    "            urls=urls, max_history_depth=max_history_depth,\n",
    "        )\n",
    "\n",
    "    @router\n",
    "    async def merge(request, sess, segment_index: int):\n",
    "        \"\"\"Merge a segment with the previous segment.\"\"\"\n",
    "        result = _merge(\n",
    "            state_store, workflow_id, request, sess, segment_index,\n",
    "            urls=urls, max_history_depth=max_history_depth,\n",
    "        )\n",
    "        if hasattr(result, '__await__'):\n",
    "            return await result\n",
    "        return result\n",
    "\n",
    "    @router\n",
    "    async def undo(request, sess):\n",
    "        \"\"\"Undo the last segmentation operation.\"\"\"\n",
    "        result = _undo(state_store, workflow_id, request, sess, urls=urls)\n",
    "        if hasattr(result, '__await__'):\n",
    "            return await result\n",
    "        return result\n",
    "\n",
    "    @router\n",
    "    async def reset(request, sess):\n",
    "        \"\"\"Reset segments to the initial NLTK split result.\"\"\"\n",
    "        result = _reset(\n",
    "            state_store, workflow_id, request, sess,\n",
    "            urls=urls, max_history_depth=max_history_depth,\n",
    "        )\n",
    "        if hasattr(result, '__await__'):\n",
    "            return await result\n",
    "        return result\n",
    "\n",
    "    @router\n",
    "    async def ai_split(request, sess):\n",
    "        \"\"\"Re-run AI (NLTK) sentence splitting on all current text.\"\"\"\n",
    "        return await _ai_split(\n",
    "            state_store, workflow_id, segmentation_service, request, sess,\n",
    "            urls=urls, max_history_depth=max_history_depth,\n",
    "        )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Route Dict\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    routes = {\n",
    "        \"init\": init,\n",
    "        \"split\": split,\n",
    "        \"merge\": merge,\n",
    "        \"undo\": undo,\n",
    "        \"reset\": reset,\n",
    "        \"ai_split\": ai_split,\n",
    "    }\n",
    "\n",
    "    return router, routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dh-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
